# ä¸€ã€ç¯å¢ƒé…ç½®
## 1. OpenAIç¯å¢ƒå˜é‡
Windows å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
setx OPENAI_BASE_URL "https://api.openai.com/v1"
setx OPENAI_API_KEY "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```
Mac å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
export OPENAI_API_KEY='https://api.openai.com/v1'
export OPENAI_API_KEY='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
```
## 2. ç›¸å…³å®‰è£…
 - Apifox
 - Postman
 - Python(3.12)
 - Pycharm
# äºŒã€æ¥å£
## 1. Model
 - æŸ¥è¯¢æ¨¡å‹åˆ—è¡¨
## 2. Chat
 - gpt-3.5-turbo
 - gpt-4o
## 3. Audio
 - tts-1ï¼ˆåˆ›å»ºè¯­éŸ³ï¼‰
 - whisper-1ï¼ˆåˆ›å»ºè½¬å½•ã€åˆ›å»ºç¿»è¯‘ï¼‰
## 4. Image
 - dall-e-3
 - åˆ›å»ºå›¾åƒï¼ˆæ–‡ç”Ÿå›¾ï¼‰
 - åˆ›å»ºå›¾ç‰‡ç¼–è¾‘ï¼ˆå«å›¾ï¼‰
 - åˆ›å»ºå›¾åƒå˜ä½“ï¼ˆæ”¹é£æ ¼ï¼‰
## 5. Embeddings
 - text-embedding-ada-002
 - text-embedding-3-large
## ä¸‰ã€æ¥å£è°ƒç”¨
 - request: req_call.py
 - sdk: embedding/sdk_call.py
 - Embedding: embedding/sdk_text_vector.py
 - å‘é‡æ•°æ®åº“æ–‡æœ¬æœç´¢ï¼šembedding/search.py
 - è°ƒç”¨å…·æœ‰è§†è§‰çš„ GPT-4oä½¿ç”¨æœ¬åœ°å›¾ç‰‡: vision/online_image_to_text.py
 - JSON æ¨¡å¼: json/json_mode.py
 - seed å¯é‡ç°è¾“å‡º: seed/seed.py
 - ä½¿ç”¨ä»£ç ç»Ÿè®¡ token æ•°é‡å¼€å‘æ§åˆ¶å°å¾ªç¯èŠå¤©: tiktoken/count_token.py
 - å®ç°åŸºäºæœ€å¤§ token æ•°é‡çš„æ¶ˆæ¯åˆ—è¡¨é™åˆ¶å¸¦ä¼šè¯é•¿åº¦ç®¡ç†çš„æ§åˆ¶å°å¾ªç¯èŠå¤©: limit_token.py
## å››ã€LangChain
LangChain æ˜¯â¼€ä¸ªâ½¤äºå¼€å‘ç”±â¼¤å‹è¯­â¾”æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„åº”â½¤ç¨‹åºçš„æ¡†æ¶ã€‚

LangChain ç®€åŒ–äº†LLMåº”â½¤ç¨‹åºâ½£å‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼š
 - å¼€å‘ï¼šä½¿â½¤LangChainçš„å¼€æºæ„å»ºæ¨¡å—å’Œç»„ä»¶æ„å»ºæ‚¨çš„åº”â½¤ç¨‹åºã€‚åˆ©â½¤ç¬¬ä¸‰â½…é›†æˆå’Œæ¨¡æ¿å¿«é€Ÿ
å¯åŠ¨ã€‚
 - â½£äº§éƒ¨ç½²ï¼šä½¿â½¤LangSmithæ£€æŸ¥ã€ç›‘æ§å’Œè¯„ä¼°æ‚¨çš„é“¾ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥æŒç»­ä¼˜åŒ–å¹¶â¾ƒä¿¡åœ°éƒ¨ç½²ã€‚
 - éƒ¨ç½²ï¼šä½¿â½¤LangServeå°†ä»»ä½•é“¾è½¬æ¢ä¸ºAPIã€‚
### 1. LCEL(D5/LCEL)
 - Runnable interface
 - Stream
### 2. LLM apps debug: LangSmith Tracing & Verbose, Debug Mode(D5/debug)
 - LangSmith Tracing:debug/lang_smith.py
 - https://smith.langchain.com/public/a89ff88f-9ddc-4757-a395-3a1b365655bf/r
 - å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
#windowså¯¼â¼Šç¯å¢ƒå˜é‡
setx LANGCHAIN_TRACING_V2 "true"
setx LANGCHAIN_API_KEY "..."
setx TAVILY_API_KEY "..."

#mac å¯¼â¼Šç¯å¢ƒå˜é‡
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
export TAVILY_API_KEY="..."
```
### 3. Start LangSmith(D5/debug/lang_smith.py)
 - Create new langsmith api key
 - Install dependencies
```bash
pip install -U langchain langchain-openai
```
 - Configure environment to connect to LangSmith.
```bash
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="<>"
LANGSMITH_PROJECT="pr-standard-loincloth-39"
OPENAI_API_KEY="<your-openai-api-key>"
```
 - Run any LLM, Chat model, or Chain. Its trace will be sent to this project.
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI()
llm.invoke("Hello, world!")
```
### 4. LangServe(D6/langserve)
LangServe ğŸ¦œ ğŸ“ å¸®åŠ©å¼€å‘è€…å°† LangChain å¯è¿â¾å’Œé“¾éƒ¨ç½²ä¸º REST APIã€‚

è¯¥åº“é›†æˆäº† FastAPI å¹¶ä½¿â½¤ pydantic è¿›â¾æ•°æ®éªŒè¯ã€‚

ä» LangChain å¯¹è±¡**â¾ƒåŠ¨æ¨æ–­è¾“â¼Šå’Œè¾“å‡ºæ¨¡å¼**ï¼Œå¹¶åœ¨æ¯æ¬¡ API è°ƒâ½¤ä¸­æ‰§â¾ï¼Œæä¾›ä¸°å¯Œçš„é”™è¯¯ä¿¡æ¯

#### 4.1 å®‰è£…
```bash
pip install "langserve[all]"
```
æˆ–è€…å¯¹äºå®¢æˆ·ç«¯ä»£ç ï¼Œ pip install "langserve[client]" ï¼Œå¯¹äºæœåŠ¡å™¨ä»£ç ï¼Œ pip in
stall "langserve[server]" ã€‚

#### 4.2 LangChain CLI
ä½¿â½¤ LangChain CLI å¿«é€Ÿå¯åŠ¨ LangServe é¡¹â½¬ã€‚

è¦ä½¿â½¤ langchain CLIï¼Œè¯·ç¡®ä¿å·²å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ langchain-cli ã€‚æ‚¨å¯ä»¥ä½¿â½¤ pip inst
all -U langchain-cli è¿›â¾å®‰è£…ã€‚

```bash
pip install -U langchain-cli

langchain -v # æŸ¥çœ‹ç‰ˆæœ¬å·
```
#### 4.3 è®¾ç½®
ä½¿â½¤ poetry è¿›â¾ä¾èµ–ç®¡ç†ã€‚
 - ä½¿â½¤ langchain cli å‘½ä»¤åˆ›å»ºæ–°åº”â½¤
```bash
langchain app new my-app
```
 - åœ¨ add_routes ä¸­å®šä¹‰å¯è¿â¾å¯¹è±¡ã€‚è½¬åˆ° server.py å¹¶ç¼–è¾‘
```bash
add_routes(app. NotImplemented)
```
 - ä½¿â½¤ poetry æ·»åŠ ç¬¬ä¸‰â½…åŒ…ï¼ˆä¾‹å¦‚ langchain-openaiã€langchain-anthropicã€
   langchain-mistral ç­‰ï¼‰
```bash
# å®‰è£…pipxï¼Œå‚è€ƒï¼šhttps://pipx.pypa.io/stable/installation/
pip install pipx
# åŠ â¼Šåˆ°ç¯å¢ƒå˜é‡ï¼Œéœ€è¦é‡å¯PyCharm 
pipx ensurepath
# å®‰è£…poetryï¼Œå‚è€ƒï¼šhttps://python-poetry.org/docs/
pipx install poetry
# å®‰è£… langchain-openai åº“ï¼Œä¾‹å¦‚ï¼špoetry add [package-name]
poetry add langchain-openai
```
 - è®¾ç½®ç›¸å…³ç¯å¢ƒå˜é‡ã€‚ä¾‹å¦‚:
```bash
export OPENAI_API_KEY="sk-..."
```
 - å¯åŠ¨æ‚¨çš„åº”â½¤
```bash
poetry run langchain serve --port=8000
```
#### 4.4 åº”ç”¨
 - æœåŠ¡å™¨

éƒ¨ç½² OpenAI èŠå¤©æ¨¡å‹ï¼Œè®²è¿°æœ‰å…³ç‰¹å®šä¸»é¢˜ç¬‘è¯çš„é“¾çš„æœåŠ¡å™¨ã€‚
```python
#!/usr/bin/env python
from fastapi import FastAPI
from langchain_openai import ChatOpenAI
from langserve import add_routes
app = FastAPI(
   title="LangChain æœåŠ¡å™¨",
   version="1.0",
   description="ä½¿â½¤ Langchain çš„ Runnable æ¥â¼çš„ç®€å• API æœåŠ¡å™¨",
)

add_routes(
   app,
   ChatOpenAI(model_name="gpt-4"),
   path="/openai",
)

if __name__ == "__main__":
   import uvicorn
   uvicorn.run(app, host="localhost", port=8000)
```
ä»æµè§ˆå™¨è°ƒâ½¤æ‚¨çš„ç«¯ç‚¹ï¼Œè¿˜éœ€è¦è®¾ç½® CORS å¤´ã€‚(ä½¿â½¤ FastAPI çš„å†…ç½®ä¸­é—´ä»¶æ¥å®ç°)
```python
from fastapi.middleware.cors import CORSMiddleware
# è®¾ç½®æ‰€æœ‰å¯â½¤ CORS çš„æ¥æº
app.add_middleware(
   CORSMiddleware,
   allow_origins=["*"],
   allow_credentials=True,
   allow_methods=["*"],
   allow_headers=["*"],
   expose_headers=["*"],
)
```
 - æ–‡æ¡£

â½‚æ¡£åœ°å€ï¼šhttp://localhost:8000/docs
 - å®¢æˆ·ç«¯

Python SDK
```python
from langchain.schema.runnable import RunnableMap
from langchain_core.prompts import ChatPromptTemplate
from langserve import RemoteRunnable

openai = RemoteRunnable("http://localhost:8000/openai/")
prompt = ChatPromptTemplate.from_messages([("system", "ä½ æ˜¯â¼€ä¸ªå–œæ¬¢å†™æ•…äº‹çš„åŠ©â¼¿"), ("system", "å†™â¼€ä¸ªæ•…äº‹ï¼Œä¸»é¢˜æ˜¯ï¼š {topic}")])
# å¯ä»¥å®šä¹‰â¾ƒå®šä¹‰é“¾
chain = prompt | RunnableMap({
 "openai": openai
})
response = chain.batch([{"topic": "çŒ«"}])
print(response)
```
åœ¨ TypeScript ä¸­ï¼ˆéœ€è¦ LangChain.js ç‰ˆæœ¬ 0.0.166 æˆ–æ›´â¾¼ï¼‰ï¼š
```typescript
import { RemoteRunnable } from "@langchain/core/runnables/remote";
const chain = new RemoteRunnable({
 url: `http://localhost:8000/openai/`,
});
const result = await chain.invoke({
 topic: "cats",
});
```
ä½¿â½¤ requests çš„ Python ä»£ç ï¼š
```python
import requests
response = requests.post(
   "http://localhost:8000/openai",
   json={'input': {'topic': 'cats'}}
)
response.json()
```
curl
```bash
curl --location --request POST 'http://localhost:8000/openai/stream' \
   --header 'Content-Type: application/json' \
   --data-raw '{
      "input": {
      "topic": "ç‹—"
      }
   }'
```
 - ç«¯ç‚¹
```python
...
add_routes(
   app,
   runnable,
   path="/my_runnable",
)
```
å°†ä»¥ä¸‹ç«¯ç‚¹æ·»åŠ åˆ°æœåŠ¡å™¨ï¼š
 - POST /my_runnable/invoke - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¯è¿â¾é¡¹
 - POST /my_runnable/batch - å¯¹â¼€æ‰¹è¾“â¼Šè°ƒâ½¤å¯è¿â¾é¡¹
 - POST /my_runnable/stream - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¹¶æµå¼ä¼ è¾“è¾“å‡º
 - POST /my_runnable/stream_log - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¹¶æµå¼ä¼ è¾“è¾“å‡ºï¼ŒåŒ…æ‹¬â½£æˆçš„ä¸­é—´æ­¥éª¤çš„è¾“å‡º
 - POST /my_runnable/astream_events - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¹¶åœ¨â½£æˆæ—¶æµå¼ä¼ è¾“äº‹ä»¶ï¼ŒåŒ…æ‹¬æ¥â¾ƒä¸­é—´æ­¥éª¤çš„äº‹ä»¶ã€‚
 - GET /my_runnable/input_schema - å¯è¿â¾é¡¹çš„è¾“â¼Šçš„ JSON æ¨¡å¼
 - GET /my_runnable/output_schema - å¯è¿â¾é¡¹çš„è¾“å‡ºçš„ JSON æ¨¡å¼
 - GET /my_runnable/config_schema - å¯è¿â¾é¡¹çš„é…ç½®çš„ JSON æ¨¡å¼

è¿™äº›ç«¯ç‚¹ä¸LangChain è¡¨è¾¾å¼è¯­â¾”æ¥â¼ç›¸åŒ¹é…

 - Playground

è®¿é—®ï¼šhttp://localhost:8000/openai/playground

å¯ä»¥åœ¨ /my_runnable/playground/ æ‰¾åˆ°â¼€ä¸ªå¯è¿â¾é¡¹çš„æ¸¸ä¹åœºâ»šâ¾¯ã€‚è¿™æä¾›äº†â¼€ä¸ªç®€å•çš„ UIæ¥é…ç½®å¹¶è°ƒâ½¤å¯è¿â¾é¡¹ï¼Œå…·æœ‰æµå¼è¾“å‡ºå’Œä¸­é—´æ­¥éª¤ã€‚

### 5. MessageHistory
#### 5.1 ä¸º Chain æ·»åŠ  Message history (Memory)å•â¾åˆå§‹åŒ– chat model
(D6/chat-model/chat_history_memory.py)

å¯¹è¯çŠ¶æ€Chainä¼ é€’
 - åœ¨æ„å»ºèŠå¤©æœºå™¨â¼ˆæ—¶ï¼Œå°†å¯¹è¯çŠ¶æ€ä¼ é€’åˆ°é“¾ä¸­ä»¥åŠä»é“¾ä¸­ä¼ å‡ºå¯¹è¯çŠ¶æ€â¾„å…³é‡è¦ã€‚ 
 - RunnableWithMessageHistory ç±»è®©æˆ‘ä»¬èƒ½å¤Ÿå‘æŸäº›ç±»å‹çš„é“¾ä¸­æ·»åŠ æ¶ˆæ¯å†å²ã€‚å®ƒåŒ…è£…å¦â¼€ä¸ª Runnable å¹¶ç®¡ç†å…¶èŠå¤©æ¶ˆæ¯å†å²ã€‚
 - å…·ä½“æ¥è¯´ï¼Œå®ƒå¯â½¤äºä»»ä½•æ¥å—ä»¥ä¸‹ä¹‹â¼€ä½œä¸ºè¾“â¼Šçš„ Runnableï¼š
   - â¼€ç³»åˆ— BaseMessages
   - å…·æœ‰ä»¥åºåˆ— BaseMessages ä½œä¸ºå€¼çš„é”®çš„å­—å…¸
   - å…·æœ‰ä»¥å­—ç¬¦ä¸²æˆ–åºåˆ— BaseMessages ä½œä¸ºæœ€æ–°æ¶ˆæ¯çš„å€¼çš„é”®å’Œâ¼€ä¸ªæ¥å—å†å²æ¶ˆæ¯çš„å•ç‹¬é”®
     çš„å­—å…¸
 - å¹¶å°†ä»¥ä¸‹ä¹‹â¼€ä½œä¸ºè¾“å‡ºè¿”å›ï¼š
   - å¯è§†ä¸º AIMessage å†…å®¹çš„å­—ç¬¦ä¸²
   - â¼€ç³»åˆ— BaseMessage
   - å…·æœ‰åŒ…å«â¼€ç³»åˆ— BaseMessage çš„é”®çš„å­—å…¸

èŠå¤©å†å²å­˜å‚¨åœ¨å†…å­˜
 - æˆ‘ä»¬æ„å»ºâ¼€ä¸ªåä¸º get_session_history çš„å¯è°ƒâ½¤å¯¹è±¡ï¼Œå¼•â½¤æ­¤å­—å…¸ä»¥è¿”å› ChatMessageHistory å®ä¾‹ã€‚
 - é€šè¿‡åœ¨è¿â¾æ—¶å‘ RunnableWithMessageHistory ä¼ é€’é…ç½®ï¼Œå¯ä»¥æŒ‡å®šå¯è°ƒâ½¤å¯¹è±¡çš„å‚æ•°ã€‚
 - é»˜è®¤æƒ…å†µä¸‹ï¼ŒæœŸæœ›é…ç½®å‚æ•°æ˜¯â¼€ä¸ªå­—ç¬¦ä¸² session_id ã€‚å¯ä»¥é€šè¿‡ history_factory_config å…³é”®å­—å‚æ•°è¿›â¾è°ƒæ•´ã€‚

#### 5.2 åŸºäº LangChain çš„ Chatbot: Chat History
(D6/chat-model/chat_history_config.py)

é…ç½®ä¼šè¯å”¯â¼€é”®
 - æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘ history_factory_config å‚æ•°ä¼ é€’â¼€ä¸ª ConfigurableFieldSpec å¯¹è±¡åˆ—è¡¨
 - æ¥â¾ƒå®šä¹‰è·Ÿè¸ªæ¶ˆæ¯å†å²çš„é…ç½®å‚æ•°ã€‚
 - ä¸‹â¾¯æˆ‘ä»¬ä½¿â½¤äº†ä¸¤ä¸ªå‚æ•°ï¼š user_id å’Œ conversation_id ã€‚
 - é…ç½®user_idå’Œconversation_idä½œä¸ºä¼šè¯å”¯â¼€é”®

#### 5.3 æ¶ˆæ¯æŒä¹…åŒ–
(D6/chat-model/chat_history_redis.py)

é…ç½®redisç¯å¢ƒ
```bash
pip install --upgrade --quiet redis
```
å¦‚æœæˆ‘ä»¬æ²¡æœ‰ç°æœ‰çš„ Redis éƒ¨ç½²å¯ä»¥è¿æ¥ï¼Œå¯ä»¥å¯åŠ¨æœ¬åœ° Redis Stack æœåŠ¡å™¨ï¼š
```bash
docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest
```
```python
REDIS_URL = "redis://localhost:6379/0"
```
### 6. ä½¿ç”¨LangSmithè®°å½•è¿½è¸ª
 - è®¾ç½®ç¯å¢ƒå˜é‡å³å¯
```
# windowså¯¼â¼Šç¯å¢ƒå˜é‡
setx LANGCHAIN_TRACING_V2 "true"
setx LANGCHAIN_API_KEY "..."

# mac å¯¼â¼Šç¯å¢ƒå˜é‡
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```
### 7. ä¿®å‰ªèŠå¤©å†å²
è£å‰ªæ¶ˆæ¯(chatbot/chatbot_clear_history.py)
 - LLM å’ŒèŠå¤©æ¨¡å‹æœ‰é™çš„ä¸Šä¸‹â½‚çª—â¼ï¼Œå³ä½¿æ‚¨æ²¡æœ‰ç›´æ¥è¾¾åˆ°é™åˆ¶ï¼Œæ‚¨å¯èƒ½ä¹Ÿå¸Œæœ›é™åˆ¶æ¨¡å‹å¤„ç†çš„â¼²æ‰°é‡ã€‚â¼€ç§è§£å†³â½…æ¡ˆæ˜¯åªåŠ è½½å’Œå­˜å‚¨æœ€è¿‘çš„ n æ¡æ¶ˆæ¯ã€‚è®©æˆ‘ä»¬ä½¿â½¤â¼€ä¸ªå¸¦æœ‰â¼€äº›é¢„åŠ è½½æ¶ˆæ¯çš„ç¤ºä¾‹å†å²è®°å½•ã€‚
æ€»ç»“è®°å¿†(chatbot/chatbot_summarize_history.py)
 - ä½¿â½¤é¢å¤–çš„LLMè°ƒâ½¤æ¥åœ¨è°ƒâ½¤é“¾ä¹‹å‰â½£æˆå¯¹è¯æ‘˜è¦ã€‚
### 8. Track token usage Cache model responses
Track token usage(è·Ÿè¸ªtokenä½¿â½¤æƒ…å†µ)
 - ä½¿â½¤ AIMessage.response_metadata
   - è®¸å¤šæ¨¡å‹æä¾›ç¨‹åºå°†ä»¤ç‰Œä½¿â½¤ä¿¡æ¯ä½œä¸ºèŠå¤©â½£æˆå“åº”çš„â¼€éƒ¨åˆ†è¿”å›ã€‚å¦‚æœå¯â½¤ï¼Œè¿™å°†åŒ…å«åœ¨
AIMessage.response_metadata å­—æ®µä¸­ã€‚
 - ä½¿â½¤å›è°ƒ
   - è¿˜æœ‰â¼€äº›ç‰¹å®šäº API çš„å›è°ƒä¸Šä¸‹â½‚ç®¡ç†å™¨ï¼Œå…è®¸è·Ÿè¸ªå¤šä¸ªè°ƒâ½¤ä¸­çš„ä»¤ç‰Œä½¿â½¤æƒ…å†µã€‚â½¬å‰ä»…ä¸º
     OpenAI API å’Œ Bedrock Anthropic API å®ç°äº†æ­¤åŠŸèƒ½ã€‚
## äº”ã€Multimode é›†æˆ
### 1. å¤šæ¨¡æ€æ•°æ®æ•°æ®ä¼ è¾“
å°†è¦æ±‚æ¨¡å‹æè¿°â¼€å¹…å›¾åƒã€‚(multimode)

æœ€å¸¸â½€æŒçš„ä¼ â¼Šå›¾åƒçš„â½…å¼æ˜¯å°†å…¶ä½œä¸ºå­—èŠ‚å­—ç¬¦ä¸²ä¼ â¼Šã€‚(multimode/multimode_image_base64.py)

ä¼ â¼Šå¤šå¹…å›¾åƒ(multimode/multimode_image_list.py)

### 2. â¼¯å…·è°ƒâ½¤(multimode/tools_call.py)
## å…­ã€Output parsers: JSON, XML, YAML
output-parser
## ä¸ƒã€è‡ªå®šä¹‰Toolsï¼Œè°ƒâ½¤ Toolsé›†æˆå†…å»º Tools
### 1. è‡ªå®šä¹‰Tools(tools)
LangChain æä¾›äº†ä¸‰ç§åˆ›å»ºâ¼¯å…·çš„â½…å¼ï¼š
1. ä½¿â½¤@toolè£…é¥°å™¨ -- å®šä¹‰â¾ƒå®šä¹‰â¼¯å…·çš„æœ€ç®€å•â½…å¼ã€‚
2. ä½¿â½¤StructuredTool.from_function ç±»â½…æ³• -- è¿™ç±»ä¼¼äº @tool è£…é¥°å™¨ï¼Œä½†å…è®¸æ›´å¤šé…ç½®å’ŒåŒæ­¥å’Œå¼‚æ­¥å®ç°çš„è§„èŒƒã€‚
3. é€šè¿‡â¼¦ç±»åŒ–BaseTool -- è¿™æ˜¯æœ€çµæ´»çš„â½…æ³•ï¼Œå®ƒæä¾›äº†æœ€â¼¤ç¨‹åº¦çš„æ§åˆ¶ï¼Œä½†éœ€è¦æ›´å¤šçš„â¼¯ä½œé‡å’Œä»£ç ã€‚ @tool æˆ– StructuredTool.from_function ç±»â½…æ³•å¯¹äºâ¼¤å¤šæ•°â½¤ä¾‹åº”è¯¥â¾œå¤Ÿäº†ã€‚ æç¤º å¦‚æœâ¼¯å…·å…·æœ‰ç²¾â¼¼é€‰æ‹©çš„åç§°ã€æè¿°å’Œ JSON æ¨¡å¼ï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šæ›´å¥½ã€‚
### 2. è°ƒâ½¤ Toolsé›†æˆå†…å»º Tools(tools_integrate)
https://python.langchain.com/v0.2/docs/integrations/tools/
## å…«ã€åˆ›å»ºå’Œè¿è¡Œ Agent
å•ç‹¬æ¥è¯´ï¼Œè¯­â¾”æ¨¡å‹â½†æ³•é‡‡å–â¾åŠ¨ - å®ƒä»¬åªèƒ½è¾“å‡ºâ½‚æœ¬ã€‚

LangChain çš„â¼€ä¸ªé‡è¦â½¤ä¾‹æ˜¯åˆ›å»ºä»£ç†ã€‚

ä»£ç†æ˜¯ä½¿â½¤ LLM ä½œä¸ºæ¨ç†å¼•æ“çš„ç³»ç»Ÿï¼Œâ½¤äºç¡®å®šåº”é‡‡å–å“ªäº›â¾åŠ¨ä»¥åŠè¿™äº›â¾åŠ¨çš„è¾“â¼Šåº”è¯¥æ˜¯ä»€
ä¹ˆã€‚

ç„¶åå¯ä»¥å°†è¿™äº›â¾åŠ¨çš„ç»“æœåé¦ˆç»™ä»£ç†ï¼Œå¹¶ç¡®å®šæ˜¯å¦éœ€è¦æ›´å¤šâ¾åŠ¨ï¼Œæˆ–è€…æ˜¯å¦å¯ä»¥ç»“æŸã€‚

æ„å»ºâ¼€ä¸ªå¯ä»¥ä¸å¤šç§ä¸åŒâ¼¯å…·è¿›â¾äº¤äº’çš„ä»£ç†ï¼šâ¼€ä¸ªæ˜¯æœ¬åœ°æ•°æ®åº“ï¼Œå¦â¼€ä¸ªæ˜¯æœç´¢å¼•æ“ã€‚æ‚¨å°†èƒ½å¤Ÿå‘è¯¥ä»£ç†æé—®ï¼Œè§‚å¯Ÿå®ƒè°ƒâ½¤â¼¯å…·ï¼Œå¹¶ä¸å®ƒè¿›â¾å¯¹è¯ã€‚

 - ä½¿â½¤è¯­â¾”æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬çš„â¼¯å…·è°ƒâ½¤èƒ½â¼’
 - åˆ›å»ºæ£€ç´¢å™¨ä»¥å‘æˆ‘ä»¬çš„ä»£ç†å…¬å¼€ç‰¹å®šä¿¡æ¯
 - ä½¿â½¤æœç´¢â¼¯å…·åœ¨çº¿æŸ¥æ‰¾ä¿¡æ¯
 - èŠå¤©å†å²ï¼Œå…è®¸èŠå¤©æœºå™¨â¼ˆâ€œè®°ä½â€è¿‡å»çš„äº¤äº’ï¼Œå¹¶åœ¨å›ç­”åç»­é—®é¢˜æ—¶è€ƒè™‘å®ƒä»¬ã€‚
 - ä½¿â½¤LangSmithè°ƒè¯•å’Œè·Ÿè¸ªåº”â½¤ç¨‹åº
### 1. å®‰è£…LangChain
```bash
pip install langchain
```
### 2. LangSmith
```bash
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```
### 3. å®šä¹‰å·¥å…·
Tavilyï¼ˆâ½¤äºåœ¨çº¿æœç´¢ï¼‰ï¼Œç„¶åæ˜¯æˆ‘ä»¬å°†åˆ›å»ºçš„æœ¬åœ°ç´¢å¼•ä¸Šçš„æ£€ç´¢å™¨ã€‚
#### 3.1 Tavily(â½¤äºåœ¨çº¿æœç´¢)
LangChain ä¸­æœ‰â¼€ä¸ªå†…ç½®â¼¯å…·ï¼Œå¯ä»¥è½»æ¾ä½¿â½¤ Tavily æœç´¢å¼•æ“ä½œä¸ºâ¼¯å…·ã€‚
```bash
export TAVILY_API_KEY="..."
```
```python
from langchain_community.tools.tavily_search import TavilySearchResults
search = TavilySearchResults(max_results=2)
print(search.invoke("ä»Šå¤©ä¸Šæµ·å¤©â½“æ€ä¹ˆæ ·"))

"""
[{'url': 'http://sh.cma.gov.cn/sh/tqyb/jrtq/', 'content': 'ä¸Šæµ·ä»Šå¤©â½“æ¸©åº¦30â„ƒ
ï½38â„ƒï¼Œåå—â»›â»›â¼’4-5çº§ï¼Œæœ‰å¤šäº‘å’Œé›·é˜µâ¾¬çš„å¯èƒ½ã€‚â½£æ´»â½“è±¡æŒ‡æ•°æ˜¾ç¤ºï¼Œâ½“æ¸©â¾¼ï¼Œâ¼ˆä½“æ„Ÿè§‰ä¸èˆ’é€‚ï¼Œ
ä¸é€‚å®œæˆ·å¤–æ´»åŠ¨ã€‚'}]
"""
```
#### 3.2 Retriever
Retriever æ˜¯ langchain åº“ä¸­çš„â¼€ä¸ªæ¨¡å—ï¼Œâ½¤äºæ£€ç´¢â¼¯å…·ã€‚æ£€ç´¢â¼¯å…·çš„ä¸»è¦â½¤é€”æ˜¯ä»â¼¤å‹â½‚æœ¬é›†åˆæˆ–çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚å®ƒä»¬é€šå¸¸â½¤äºé—®ç­”ç³»ç»Ÿã€å¯¹è¯ä»£ç†å’Œå…¶ä»–éœ€è¦ä»â¼¤é‡â½‚æœ¬æ•°æ®ä¸­æå–ä¿¡æ¯çš„åº”â½¤ç¨‹åºã€‚
```python
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
loader = WebBaseLoader("https://zh.wikipedia.org/wiki/%E7%8C%AB")
docs = loader.load()
documents = RecursiveCharacterTextSplitter(
 # chunk_size å‚æ•°åœ¨ RecursiveCharacterTextSplitter ä¸­â½¤äºæŒ‡å®šæ¯ä¸ªâ½‚æ¡£å—çš„æœ€â¼¤å­—ç¬¦æ•°ã€‚å®ƒçš„ä½œâ½¤ä¸»è¦æœ‰ä»¥ä¸‹â¼ä¸ªâ½…â¾¯ï¼š
 # chunk_overlap å‚æ•°â½¤äºæŒ‡å®šæ¯ä¸ªâ½‚æ¡£å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ã€‚è¿™æ„å‘³ç€ï¼Œå½“â½‚æ¡£è¢«æ‹†åˆ†æˆè¾ƒâ¼©çš„å—æ—¶ï¼Œæ¯ä¸ªå—çš„æœ«å°¾éƒ¨åˆ†ä¼šä¸ä¸‹â¼€ä¸ªå—çš„å¼€å¤´éƒ¨åˆ†æœ‰â¼€å®šæ•°é‡çš„é‡å å­—ç¬¦ã€‚
 # ç¬¬â¼€ä¸ªå—åŒ…å«å­—ç¬¦ 1 åˆ° 1000ã€‚ç¬¬â¼†ä¸ªå—åŒ…å«å­—ç¬¦ 801 åˆ° 1800ã€‚ç¬¬ä¸‰ä¸ªå—åŒ…å«å­—ç¬¦ 1601 åˆ° 2600ã€‚
 chunk_size=1000, chunk_overlap=200
).split_documents(docs)
vector = FAISS.from_documents(documents, OpenAIEmbeddings())
retriever = vector.as_retriever()

retriever.invoke("çŒ«çš„ç‰¹å¾")[0]

"""
page_content='è½è¦º[ç¼–è¾‘]
è²“æ¯éš»â½¿å„æœ‰32æ¢ç¨â½´çš„è‚Œâ¾æ§åˆ¶â½¿æ®¼è½‰å‹•ï¼Œå› æ­¤é›™â½¿å¯å–®ç¨æœå‘ä¸åŒçš„â¾³æºè½‰å‹•ï¼Œä½¿å…¶å‘çµç‰©ç§»å‹•
æ™‚ä»èƒ½å°å‘¨é­å…¶ä»–â¾³æºä¿æŒç›´æ¥æ¥è§¸ã€‚[50] é™¤äº†è˜‡æ ¼è˜­æŠ˜â½¿è²“é€™é¡åŸºå› çªè®Šçš„è²“ä»¥å¤–ï¼Œè²“æ¥µå°‘æœ‰ç‹—
å¸¸â¾’çš„ã€Œå‚â½¿ã€ï¼Œå¤šæ•¸çš„è²“â½¿å‘ä¸Šç›´â½´ã€‚ç•¶è²“å¿¿æ€’æˆ–å—é©šæ™‚ï¼Œâ½¿æœµæœƒè²¼å‘å¾Œâ½…ï¼Œä¸¦ç™¼å‡ºå’†å“®èˆ‡ã€Œå˜¶ã€
è²ã€‚
è²“èˆ‡â¼ˆé¡å°ä½é »è²â¾³éˆæ•åº¦ç›¸è‹¥ã€‚â¼ˆé¡ä¸­åªæœ‰æ¥µå°‘æ•¸çš„èª¿â¾³å¸«èƒ½è½åˆ°20 kHzä»¥ä¸Šçš„â¾¼é »è²â¾³ï¼ˆ8.4åº¦
çš„â¼‹åº¦â¾³ï¼‰ï¼Œè²“å‰‡å¯é”64kHzï¼ˆ10åº¦çš„â¼‹åº¦â¾³ï¼‰ï¼Œâ½â¼ˆé¡è¦â¾¼1.6å€‹â¼‹åº¦â¾³ï¼Œç”šâ¾„â½ç‹—è¦â¾¼1å€‹â¼‹åº¦ï¼›
ä½†æ˜¯è²“è¾¨åˆ¥â¾³å·®é ˆé–‹æœ€å°‘5åº¦ï¼Œâ½èµ·â¼ˆé¡è¾¨åˆ¥â¾³å·®é ˆé–‹æœ€å°‘0.5åº¦ä¾†å¾—ç²—ç–ã€‚[51][47]
å—…è¦º[ç¼–è¾‘]
å®¶è²“çš„å—…è¦ºè¼ƒâ¼ˆé¡éˆæ•14å€ã€‚[52]è²“çš„â¿è…”å…§æœ‰2å„„å€‹å—…è¦ºå—å™¨ï¼Œæ•¸é‡ç”šâ¾„è¶…éæŸäº›å“ç¨®çš„ç‹—ï¼ˆç‹—å—…
è¦ºç´°èƒç´„1.25å„„ï½2.2å„„ï¼‰ã€‚
å‘³è¦º[ç¼–è¾‘]
è²“æ—©æœŸæ¼”åŒ–æ™‚ç”±æ–¼åŸºå› çªè®Šï¼Œå¤±å»äº†ç”œçš„å‘³è¦ºï¼Œ[53]ä½†è²“ä¸å…‰èƒ½æ„ŸçŸ¥é…¸ã€è‹¦ã€é¹¹å‘³ï¼Œé€‰æ‹©é€‚åˆâ¾ƒâ¼°â¼
å‘³çš„â»ç‰©ï¼Œè¿˜èƒ½å°å‡ºâ½”çš„å‘³é“ï¼Œè¿™â¼€ç‚¹æ˜¯å…¶ä»–åŠ¨ç‰©æ‰€ä¸åŠçš„ã€‚ä¸è¿‡æ€»æ‹¬æ¥è¯´çŒ«çš„å‘³è§‰ä¸ç®—å®Œå–„ï¼Œç›¸â½
â¼€èˆ¬â¼ˆé¡å¹³å‡æœ‰9000å€‹å‘³è•¾ï¼Œè²“â¼€èˆ¬å¹³å‡åƒ…æœ‰473å€‹å‘³è•¾ä¸”ä¸å–œå¥½ä½æ–¼å®¤æº«ä¹‹â»ç‰©ã€‚æ•…æ­¤ï¼Œè²“è¾¨èªâ»
ç‰©ä¹ƒæ†‘å—…è¦ºå¤šæ–¼å‘³è¦ºã€‚[47]
è§¸è¦º[ç¼–è¾‘]
è²“åœ¨ç£¨è¹­æ™‚èº«ä¸Šæœƒæ•£ç™¼å‡ºç‰¹åˆ¥çš„è²»æ´›è’™ï¼Œç•¶é€™äº›ç¨æœ‰çš„è²»æ´›è’™ç•™ä¸‹æ™‚ï¼Œâ½¬çš„å°±æ˜¯åœ¨å®£èª“ä¸»æ¬Šï¼Œæé†’å…¶
å®ƒè²“é€™æ˜¯æˆ‘çš„ï¼Œå…¶å¯¦é€™ç¨®â¾ç‚ºç®—æ˜¯â¼€ç¨®æ¨™è¨˜åœ°ç›¤çš„è±¡å¾µï¼Œæœƒè®“ç‰ å€‘æœ‰æ„Ÿåˆ°å®‰â¼¼åŠå®‰å…¨æ„Ÿã€‚
è¢«â½‘[ç¼–è¾‘]
ä¸»æ¡â½¬ï¼šè²“çš„â½‘â¾Šéºå‚³å’Œé¡â¾Š
â»‘åº¦[ç¼–è¾‘]
è²“ä¸»è¦å¯ä»¥ä¾æ“šè¢«â½‘â»‘åº¦åˆ†ç‚ºâ»‘â½‘è²“ï¼ŒçŸ­â½‘è²“å’Œç„¡â½‘è²“ã€‚' metadata={'source': 'https://z
h.wikipedia.org/wiki/%E7%8C%AB', 'title': 'çŒ« - ç»´åŸºç™¾ç§‘ï¼Œâ¾ƒç”±çš„ç™¾ç§‘å…¨ä¹¦', 'la
nguage': 'zh'}
"""
```
å¡«å……äº†æˆ‘ä»¬å°†è¦è¿›â¾Retrieverçš„ç´¢å¼•ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°å°†å…¶è½¬æ¢ä¸ºâ¼€ä¸ªâ¼¯å…·ï¼ˆä»£ç†ç¨‹åºæ­£ç¡®ä½¿â½¤æ‰€éœ€çš„æ ¼å¼ï¼‰
```python
from langchain.tools.retriever import create_retriever_tool

retriever_tool = create_retriever_tool(
   retriever,
   "wiki_search",
   "æœç´¢ç»´åŸºç™¾ç§‘",
)
```
ä½¿â½¤è¯­â¾”æ¨¡å‹
```python
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model_name="gpt-4")

from langchain_core.messages import HumanMessage
response = model.invoke([HumanMessage(content="hi!")])
response.content

"""
'Hello! How can I assist you today?'
"""

model_with_tools = model.bind_tools(tools)

response = model_with_tools.invoke([HumanMessage(content="ä»Šå¤©ä¸Šæµ·å¤©â½“æ€ä¹ˆæ ·")
                                    ])
print(f"ContentString: {response.content}")
print(f"ToolCalls: {response.tool_calls}")

"""
ContentString:
ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'ä»Šå¤©ä¸Š
æµ·å¤©â½“'}, 'id': 'call_EOxYscVIVjttlbztWoR1CvTm', 'type': 'tool_call'}]
"""
```
### 4. åˆ›å»ºä»£ç†ç¨‹åº
```python
from langchain.agents import create_tool_calling_agent
agent = create_tool_calling_agent(model, tools, prompt)

from langchain.agents import AgentExecutor
agent_executor = AgentExecutor(agent=agent, tools=tools)
```
### 5. è¿è¡Œä»£ç†
```python
print(agent_executor.invoke({"input": "ä½ å¥½"}))

"""
{'input': 'ä½ å¥½', 'output': 'ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'}
"""
```
### 6. æ·»åŠ è®°å¿†
```python
from langchain_core.messages import AIMessage, HumanMessage
agent_executor.invoke(
   {
      "chat_history": [
         HumanMessage(content="hi! my name is bob"),
         AIMessage(content="ä½ å¥½Bobï¼æˆ‘ä»Šå¤©èƒ½å¸®ä½ ä»€ä¹ˆï¼Ÿ"),
      ],
      "input": "æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆ?",
   }
)
```
```python
agent_with_chat_history = RunnableWithMessageHistory(
 agent_executor,
 get_session_history,
 input_messages_key="input",
 history_messages_key="chat_history",
)

response = agent_with_chat_history.invoke(
   {"input": "Hiï¼Œæˆ‘çš„åå­—æ˜¯Cyber"},
   config={"configurable": {"session_id": "123"}},
)
```
## ä¹ã€Embedding
embedding-models
## åã€RAG
æ£€ç´¢å¢å¼ºâ½£æˆï¼ˆRAGï¼‰æ˜¯æŒ‡å¯¹â¼¤å‹è¯­â¾”æ¨¡å‹è¾“å‡ºè¿›â¾ä¼˜åŒ–ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨â½£æˆå“åº”ä¹‹å‰å¼•â½¤è®­ç»ƒæ•°æ®æ¥æºä¹‹å¤–çš„æƒå¨çŸ¥è¯†åº“ã€‚â¼¤å‹è¯­â¾”æ¨¡å‹ï¼ˆLLMï¼‰â½¤æµ·é‡æ•°æ®è¿›â¾è®­ç»ƒï¼Œä½¿â½¤æ•°â¼—äº¿ä¸ªå‚æ•°ä¸ºå›ç­”é—®é¢˜ã€ç¿»è¯‘è¯­â¾”å’Œå®Œæˆå¥â¼¦ç­‰ä»»åŠ¡â½£æˆåŸå§‹è¾“å‡ºã€‚åœ¨ LLM æœ¬å°±å¼ºâ¼¤çš„åŠŸèƒ½åŸºç¡€ä¸Šï¼ŒRAG å°†å…¶æ‰©å±•ä¸ºèƒ½è®¿é—®ç‰¹å®šé¢†åŸŸæˆ–ç»„ç»‡çš„å†…éƒ¨çŸ¥è¯†åº“ï¼Œæ‰€æœ‰è¿™äº›éƒ½â½†éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚è¿™æ˜¯â¼€ç§ç»æµâ¾¼æ•ˆåœ°æ”¹è¿› LLM è¾“å‡ºçš„â½…æ³•ï¼Œè®©å®ƒåœ¨å„ç§æƒ…å¢ƒä¸‹éƒ½èƒ½ä¿æŒç›¸å…³æ€§ã€å‡†ç¡®æ€§å’Œå®â½¤æ€§ã€‚

### AIåŠ©æ‰‹ï¼šå°å¸½é—®ç­”App(D9/rag-app)
```bash
streamlit run ./txt_search.py --server.port 1234
```


