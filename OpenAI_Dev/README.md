# ä¸€ã€ç¯å¢ƒé…ç½®
## 1. OpenAIç¯å¢ƒå˜é‡
Windows å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
setx OPENAI_BASE_URL "https://api.openai.com/v1"
setx OPENAI_API_KEY "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```
Mac å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
export OPENAI_API_KEY='https://api.openai.com/v1'
export OPENAI_API_KEY='sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
```
## 2. ç›¸å…³å®‰è£…
 - Apifox
 - Postman
 - Python(3.12)
 - Pycharm
# äºŒã€æ¥å£
## 1. Model
 - æŸ¥è¯¢æ¨¡å‹åˆ—è¡¨
## 2. Chat
 - gpt-3.5-turbo
 - gpt-4o
## 3. Audio
 - tts-1ï¼ˆåˆ›å»ºè¯­éŸ³ï¼‰
 - whisper-1ï¼ˆåˆ›å»ºè½¬å½•ã€åˆ›å»ºç¿»è¯‘ï¼‰
## 4. Image
 - dall-e-3
 - åˆ›å»ºå›¾åƒï¼ˆæ–‡ç”Ÿå›¾ï¼‰
 - åˆ›å»ºå›¾ç‰‡ç¼–è¾‘ï¼ˆå«å›¾ï¼‰
 - åˆ›å»ºå›¾åƒå˜ä½“ï¼ˆæ”¹é£æ ¼ï¼‰
## 5. Embeddings
 - text-embedding-ada-002
 - text-embedding-3-large
## ä¸‰ã€æ¥å£è°ƒç”¨
 - request: req_call.py
 - sdk: embedding/sdk_call.py
 - Embedding: embedding/sdk_text_vector.py
 - å‘é‡æ•°æ®åº“æ–‡æœ¬æœç´¢ï¼šembedding/search.py
 - è°ƒç”¨å…·æœ‰è§†è§‰çš„ GPT-4oä½¿ç”¨æœ¬åœ°å›¾ç‰‡: vision/online_image_to_text.py
 - JSON æ¨¡å¼: json/json_mode.py
 - seed å¯é‡ç°è¾“å‡º: seed/seed.py
 - ä½¿ç”¨ä»£ç ç»Ÿè®¡ token æ•°é‡å¼€å‘æ§åˆ¶å°å¾ªç¯èŠå¤©: tiktoken/count_token.py
 - å®ç°åŸºäºæœ€å¤§ token æ•°é‡çš„æ¶ˆæ¯åˆ—è¡¨é™åˆ¶å¸¦ä¼šè¯é•¿åº¦ç®¡ç†çš„æ§åˆ¶å°å¾ªç¯èŠå¤©: limit_token.py
## å››ã€LangChain
LangChain æ˜¯â¼€ä¸ªâ½¤äºå¼€å‘ç”±â¼¤å‹è¯­â¾”æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„åº”â½¤ç¨‹åºçš„æ¡†æ¶ã€‚

LangChain ç®€åŒ–äº†LLMåº”â½¤ç¨‹åºâ½£å‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼š
 - å¼€å‘ï¼šä½¿â½¤LangChainçš„å¼€æºæ„å»ºæ¨¡å—å’Œç»„ä»¶æ„å»ºæ‚¨çš„åº”â½¤ç¨‹åºã€‚åˆ©â½¤ç¬¬ä¸‰â½…é›†æˆå’Œæ¨¡æ¿å¿«é€Ÿ
å¯åŠ¨ã€‚
 - â½£äº§éƒ¨ç½²ï¼šä½¿â½¤LangSmithæ£€æŸ¥ã€ç›‘æ§å’Œè¯„ä¼°æ‚¨çš„é“¾ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥æŒç»­ä¼˜åŒ–å¹¶â¾ƒä¿¡åœ°éƒ¨ç½²ã€‚
 - éƒ¨ç½²ï¼šä½¿â½¤LangServeå°†ä»»ä½•é“¾è½¬æ¢ä¸ºAPIã€‚
### 1. LCEL(D5/LCEL)
 - Runnable interface
 - Stream
### 2. LLM apps debug: LangSmith Tracing & Verbose, Debug Mode(D5/debug)
 - LangSmith Tracing:debug/lang_smith.py
 - https://smith.langchain.com/public/a89ff88f-9ddc-4757-a395-3a1b365655bf/r
 - å¯¼å…¥ç¯å¢ƒå˜é‡
```bash
#windowså¯¼â¼Šç¯å¢ƒå˜é‡
setx LANGCHAIN_TRACING_V2 "true"
setx LANGCHAIN_API_KEY "..."
setx TAVILY_API_KEY "..."

#mac å¯¼â¼Šç¯å¢ƒå˜é‡
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
export TAVILY_API_KEY="..."
```
### 3. Start LangSmith(D5/debug/lang_smith.py)
 - Create new langsmith api key
 - Install dependencies
```bash
pip install -U langchain langchain-openai
```
 - Configure environment to connect to LangSmith.
```bash
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="<>"
LANGSMITH_PROJECT="pr-standard-loincloth-39"
OPENAI_API_KEY="<your-openai-api-key>"
```
 - Run any LLM, Chat model, or Chain. Its trace will be sent to this project.
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI()
llm.invoke("Hello, world!")
```
### 4. LangServe(D6/langserve)
LangServe ğŸ¦œ ğŸ“ å¸®åŠ©å¼€å‘è€…å°† LangChain å¯è¿â¾å’Œé“¾éƒ¨ç½²ä¸º REST APIã€‚

è¯¥åº“é›†æˆäº† FastAPI å¹¶ä½¿â½¤ pydantic è¿›â¾æ•°æ®éªŒè¯ã€‚

ä» LangChain å¯¹è±¡**â¾ƒåŠ¨æ¨æ–­è¾“â¼Šå’Œè¾“å‡ºæ¨¡å¼**ï¼Œå¹¶åœ¨æ¯æ¬¡ API è°ƒâ½¤ä¸­æ‰§â¾ï¼Œæä¾›ä¸°å¯Œçš„é”™è¯¯ä¿¡æ¯

#### 4.1 å®‰è£…
```bash
pip install "langserve[all]"
```
æˆ–è€…å¯¹äºå®¢æˆ·ç«¯ä»£ç ï¼Œ pip install "langserve[client]" ï¼Œå¯¹äºæœåŠ¡å™¨ä»£ç ï¼Œ pip in
stall "langserve[server]" ã€‚

#### 4.2 LangChain CLI
ä½¿â½¤ LangChain CLI å¿«é€Ÿå¯åŠ¨ LangServe é¡¹â½¬ã€‚

è¦ä½¿â½¤ langchain CLIï¼Œè¯·ç¡®ä¿å·²å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ langchain-cli ã€‚æ‚¨å¯ä»¥ä½¿â½¤ pip inst
all -U langchain-cli è¿›â¾å®‰è£…ã€‚

```bash
pip install -U langchain-cli

langchain -v # æŸ¥çœ‹ç‰ˆæœ¬å·
```
#### 4.3 è®¾ç½®
ä½¿â½¤ poetry è¿›â¾ä¾èµ–ç®¡ç†ã€‚
 - ä½¿â½¤ langchain cli å‘½ä»¤åˆ›å»ºæ–°åº”â½¤
```bash
langchain app new my-app
```
 - åœ¨ add_routes ä¸­å®šä¹‰å¯è¿â¾å¯¹è±¡ã€‚è½¬åˆ° server.py å¹¶ç¼–è¾‘
```bash
add_routes(app. NotImplemented)
```
 - ä½¿â½¤ poetry æ·»åŠ ç¬¬ä¸‰â½…åŒ…ï¼ˆä¾‹å¦‚ langchain-openaiã€langchain-anthropicã€
   langchain-mistral ç­‰ï¼‰
```bash
# å®‰è£…pipxï¼Œå‚è€ƒï¼šhttps://pipx.pypa.io/stable/installation/
pip install pipx
# åŠ â¼Šåˆ°ç¯å¢ƒå˜é‡ï¼Œéœ€è¦é‡å¯PyCharm 
pipx ensurepath
# å®‰è£…poetryï¼Œå‚è€ƒï¼šhttps://python-poetry.org/docs/
pipx install poetry
# å®‰è£… langchain-openai åº“ï¼Œä¾‹å¦‚ï¼špoetry add [package-name]
poetry add langchain-openai
```
 - è®¾ç½®ç›¸å…³ç¯å¢ƒå˜é‡ã€‚ä¾‹å¦‚:
```bash
export OPENAI_API_KEY="sk-..."
```
 - å¯åŠ¨æ‚¨çš„åº”â½¤
```bash
poetry run langchain serve --port=8000
```
#### 4.4 åº”ç”¨
 - æœåŠ¡å™¨

éƒ¨ç½² OpenAI èŠå¤©æ¨¡å‹ï¼Œè®²è¿°æœ‰å…³ç‰¹å®šä¸»é¢˜ç¬‘è¯çš„é“¾çš„æœåŠ¡å™¨ã€‚
```python
#!/usr/bin/env python
from fastapi import FastAPI
from langchain_openai import ChatOpenAI
from langserve import add_routes
app = FastAPI(
   title="LangChain æœåŠ¡å™¨",
   version="1.0",
   description="ä½¿â½¤ Langchain çš„ Runnable æ¥â¼çš„ç®€å• API æœåŠ¡å™¨",
)

add_routes(
   app,
   ChatOpenAI(model_name="gpt-4"),
   path="/openai",
)

if __name__ == "__main__":
   import uvicorn
   uvicorn.run(app, host="localhost", port=8000)
```
ä»æµè§ˆå™¨è°ƒâ½¤æ‚¨çš„ç«¯ç‚¹ï¼Œè¿˜éœ€è¦è®¾ç½® CORS å¤´ã€‚(ä½¿â½¤ FastAPI çš„å†…ç½®ä¸­é—´ä»¶æ¥å®ç°)
```python
from fastapi.middleware.cors import CORSMiddleware
# è®¾ç½®æ‰€æœ‰å¯â½¤ CORS çš„æ¥æº
app.add_middleware(
   CORSMiddleware,
   allow_origins=["*"],
   allow_credentials=True,
   allow_methods=["*"],
   allow_headers=["*"],
   expose_headers=["*"],
)
```
 - æ–‡æ¡£

â½‚æ¡£åœ°å€ï¼šhttp://localhost:8000/docs
 - å®¢æˆ·ç«¯

Python SDK
```python
from langchain.schema.runnable import RunnableMap
from langchain_core.prompts import ChatPromptTemplate
from langserve import RemoteRunnable

openai = RemoteRunnable("http://localhost:8000/openai/")
prompt = ChatPromptTemplate.from_messages([("system", "ä½ æ˜¯â¼€ä¸ªå–œæ¬¢å†™æ•…äº‹çš„åŠ©â¼¿"), ("system", "å†™â¼€ä¸ªæ•…äº‹ï¼Œä¸»é¢˜æ˜¯ï¼š {topic}")])
# å¯ä»¥å®šä¹‰â¾ƒå®šä¹‰é“¾
chain = prompt | RunnableMap({
 "openai": openai
})
response = chain.batch([{"topic": "çŒ«"}])
print(response)
```
åœ¨ TypeScript ä¸­ï¼ˆéœ€è¦ LangChain.js ç‰ˆæœ¬ 0.0.166 æˆ–æ›´â¾¼ï¼‰ï¼š
```typescript
import { RemoteRunnable } from "@langchain/core/runnables/remote";
const chain = new RemoteRunnable({
 url: `http://localhost:8000/openai/`,
});
const result = await chain.invoke({
 topic: "cats",
});
```
ä½¿â½¤ requests çš„ Python ä»£ç ï¼š
```python
import requests
response = requests.post(
   "http://localhost:8000/openai",
   json={'input': {'topic': 'cats'}}
)
response.json()
```
curl
```bash
curl --location --request POST 'http://localhost:8000/openai/stream' \
   --header 'Content-Type: application/json' \
   --data-raw '{
      "input": {
      "topic": "ç‹—"
      }
   }'
```
 - ç«¯ç‚¹
```python
...
add_routes(
   app,
   runnable,
   path="/my_runnable",
)
```
å°†ä»¥ä¸‹ç«¯ç‚¹æ·»åŠ åˆ°æœåŠ¡å™¨ï¼š
 - POST /my_runnable/invoke - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¯è¿â¾é¡¹
 - POST /my_runnable/batch - å¯¹â¼€æ‰¹è¾“â¼Šè°ƒâ½¤å¯è¿â¾é¡¹
 - POST /my_runnable/stream - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¹¶æµå¼ä¼ è¾“è¾“å‡º
 - POST /my_runnable/stream_log - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¹¶æµå¼ä¼ è¾“è¾“å‡ºï¼ŒåŒ…æ‹¬â½£æˆçš„ä¸­é—´æ­¥éª¤çš„è¾“å‡º
 - POST /my_runnable/astream_events - å¯¹å•ä¸ªè¾“â¼Šè°ƒâ½¤å¹¶åœ¨â½£æˆæ—¶æµå¼ä¼ è¾“äº‹ä»¶ï¼ŒåŒ…æ‹¬æ¥â¾ƒä¸­é—´æ­¥éª¤çš„äº‹ä»¶ã€‚
 - GET /my_runnable/input_schema - å¯è¿â¾é¡¹çš„è¾“â¼Šçš„ JSON æ¨¡å¼
 - GET /my_runnable/output_schema - å¯è¿â¾é¡¹çš„è¾“å‡ºçš„ JSON æ¨¡å¼
 - GET /my_runnable/config_schema - å¯è¿â¾é¡¹çš„é…ç½®çš„ JSON æ¨¡å¼

è¿™äº›ç«¯ç‚¹ä¸LangChain è¡¨è¾¾å¼è¯­â¾”æ¥â¼ç›¸åŒ¹é…

 - Playground

è®¿é—®ï¼šhttp://localhost:8000/openai/playground

å¯ä»¥åœ¨ /my_runnable/playground/ æ‰¾åˆ°â¼€ä¸ªå¯è¿â¾é¡¹çš„æ¸¸ä¹åœºâ»šâ¾¯ã€‚è¿™æä¾›äº†â¼€ä¸ªç®€å•çš„ UIæ¥é…ç½®å¹¶è°ƒâ½¤å¯è¿â¾é¡¹ï¼Œå…·æœ‰æµå¼è¾“å‡ºå’Œä¸­é—´æ­¥éª¤ã€‚

### 5. MessageHistory
#### 5.1 ä¸º Chain æ·»åŠ  Message history (Memory)å•â¾åˆå§‹åŒ– chat model
(D6/chat-model/chat_history_memory.py)

å¯¹è¯çŠ¶æ€Chainä¼ é€’
 - åœ¨æ„å»ºèŠå¤©æœºå™¨â¼ˆæ—¶ï¼Œå°†å¯¹è¯çŠ¶æ€ä¼ é€’åˆ°é“¾ä¸­ä»¥åŠä»é“¾ä¸­ä¼ å‡ºå¯¹è¯çŠ¶æ€â¾„å…³é‡è¦ã€‚ 
 - RunnableWithMessageHistory ç±»è®©æˆ‘ä»¬èƒ½å¤Ÿå‘æŸäº›ç±»å‹çš„é“¾ä¸­æ·»åŠ æ¶ˆæ¯å†å²ã€‚å®ƒåŒ…è£…å¦â¼€ä¸ª Runnable å¹¶ç®¡ç†å…¶èŠå¤©æ¶ˆæ¯å†å²ã€‚
 - å…·ä½“æ¥è¯´ï¼Œå®ƒå¯â½¤äºä»»ä½•æ¥å—ä»¥ä¸‹ä¹‹â¼€ä½œä¸ºè¾“â¼Šçš„ Runnableï¼š
   - â¼€ç³»åˆ— BaseMessages
   - å…·æœ‰ä»¥åºåˆ— BaseMessages ä½œä¸ºå€¼çš„é”®çš„å­—å…¸
   - å…·æœ‰ä»¥å­—ç¬¦ä¸²æˆ–åºåˆ— BaseMessages ä½œä¸ºæœ€æ–°æ¶ˆæ¯çš„å€¼çš„é”®å’Œâ¼€ä¸ªæ¥å—å†å²æ¶ˆæ¯çš„å•ç‹¬é”®
     çš„å­—å…¸
 - å¹¶å°†ä»¥ä¸‹ä¹‹â¼€ä½œä¸ºè¾“å‡ºè¿”å›ï¼š
   - å¯è§†ä¸º AIMessage å†…å®¹çš„å­—ç¬¦ä¸²
   - â¼€ç³»åˆ— BaseMessage
   - å…·æœ‰åŒ…å«â¼€ç³»åˆ— BaseMessage çš„é”®çš„å­—å…¸

èŠå¤©å†å²å­˜å‚¨åœ¨å†…å­˜
 - æˆ‘ä»¬æ„å»ºâ¼€ä¸ªåä¸º get_session_history çš„å¯è°ƒâ½¤å¯¹è±¡ï¼Œå¼•â½¤æ­¤å­—å…¸ä»¥è¿”å› ChatMessageHistory å®ä¾‹ã€‚
 - é€šè¿‡åœ¨è¿â¾æ—¶å‘ RunnableWithMessageHistory ä¼ é€’é…ç½®ï¼Œå¯ä»¥æŒ‡å®šå¯è°ƒâ½¤å¯¹è±¡çš„å‚æ•°ã€‚
 - é»˜è®¤æƒ…å†µä¸‹ï¼ŒæœŸæœ›é…ç½®å‚æ•°æ˜¯â¼€ä¸ªå­—ç¬¦ä¸² session_id ã€‚å¯ä»¥é€šè¿‡ history_factory_config å…³é”®å­—å‚æ•°è¿›â¾è°ƒæ•´ã€‚

#### 5.2 åŸºäº LangChain çš„ Chatbot: Chat History
(D6/chat-model/chat_history_config.py)

é…ç½®ä¼šè¯å”¯â¼€é”®
 - æˆ‘ä»¬å¯ä»¥é€šè¿‡å‘ history_factory_config å‚æ•°ä¼ é€’â¼€ä¸ª ConfigurableFieldSpec å¯¹è±¡åˆ—è¡¨
 - æ¥â¾ƒå®šä¹‰è·Ÿè¸ªæ¶ˆæ¯å†å²çš„é…ç½®å‚æ•°ã€‚
 - ä¸‹â¾¯æˆ‘ä»¬ä½¿â½¤äº†ä¸¤ä¸ªå‚æ•°ï¼š user_id å’Œ conversation_id ã€‚
 - é…ç½®user_idå’Œconversation_idä½œä¸ºä¼šè¯å”¯â¼€é”®

#### 5.3 æ¶ˆæ¯æŒä¹…åŒ–
(D6/chat-model/chat_history_redis.py)

é…ç½®redisç¯å¢ƒ
```bash
pip install --upgrade --quiet redis
```
å¦‚æœæˆ‘ä»¬æ²¡æœ‰ç°æœ‰çš„ Redis éƒ¨ç½²å¯ä»¥è¿æ¥ï¼Œå¯ä»¥å¯åŠ¨æœ¬åœ° Redis Stack æœåŠ¡å™¨ï¼š
```bash
docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest
```
```python
REDIS_URL = "redis://localhost:6379/0"
```
### 6. ä½¿ç”¨LangSmithè®°å½•è¿½è¸ª
 - è®¾ç½®ç¯å¢ƒå˜é‡å³å¯
```
# windowså¯¼â¼Šç¯å¢ƒå˜é‡
setx LANGCHAIN_TRACING_V2 "true"
setx LANGCHAIN_API_KEY "..."

# mac å¯¼â¼Šç¯å¢ƒå˜é‡
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```
### 7. ä¿®å‰ªèŠå¤©å†å²
è£å‰ªæ¶ˆæ¯(chatbot/chatbot_clear_history.py)
 - LLM å’ŒèŠå¤©æ¨¡å‹æœ‰é™çš„ä¸Šä¸‹â½‚çª—â¼ï¼Œå³ä½¿æ‚¨æ²¡æœ‰ç›´æ¥è¾¾åˆ°é™åˆ¶ï¼Œæ‚¨å¯èƒ½ä¹Ÿå¸Œæœ›é™åˆ¶æ¨¡å‹å¤„ç†çš„â¼²æ‰°é‡ã€‚â¼€ç§è§£å†³â½…æ¡ˆæ˜¯åªåŠ è½½å’Œå­˜å‚¨æœ€è¿‘çš„ n æ¡æ¶ˆæ¯ã€‚è®©æˆ‘ä»¬ä½¿â½¤â¼€ä¸ªå¸¦æœ‰â¼€äº›é¢„åŠ è½½æ¶ˆæ¯çš„ç¤ºä¾‹å†å²è®°å½•ã€‚
æ€»ç»“è®°å¿†(chatbot/chatbot_summarize_history.py)
 - ä½¿â½¤é¢å¤–çš„LLMè°ƒâ½¤æ¥åœ¨è°ƒâ½¤é“¾ä¹‹å‰â½£æˆå¯¹è¯æ‘˜è¦ã€‚
### 8. Track token usage Cache model responses
Track token usage(è·Ÿè¸ªtokenä½¿â½¤æƒ…å†µ)
 - ä½¿â½¤ AIMessage.response_metadata
   - è®¸å¤šæ¨¡å‹æä¾›ç¨‹åºå°†ä»¤ç‰Œä½¿â½¤ä¿¡æ¯ä½œä¸ºèŠå¤©â½£æˆå“åº”çš„â¼€éƒ¨åˆ†è¿”å›ã€‚å¦‚æœå¯â½¤ï¼Œè¿™å°†åŒ…å«åœ¨
AIMessage.response_metadata å­—æ®µä¸­ã€‚
 - ä½¿â½¤å›è°ƒ
   - è¿˜æœ‰â¼€äº›ç‰¹å®šäº API çš„å›è°ƒä¸Šä¸‹â½‚ç®¡ç†å™¨ï¼Œå…è®¸è·Ÿè¸ªå¤šä¸ªè°ƒâ½¤ä¸­çš„ä»¤ç‰Œä½¿â½¤æƒ…å†µã€‚â½¬å‰ä»…ä¸º
     OpenAI API å’Œ Bedrock Anthropic API å®ç°äº†æ­¤åŠŸèƒ½ã€‚